{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customdataset(Dataset): \n",
    "    def __init__(self, data_dir, transform= None): \n",
    "        #이닛 해주고\n",
    "        self.data_dir= data_dir \n",
    "        self.transform= transform\n",
    "        #이미지들 경로명 담을 리스트\n",
    "        self.image_paths= []\n",
    "        self.labels= []\n",
    "\n",
    "        #이제 여기서 데이터를 결정해줘야해. \n",
    "        #경로에서 'NORMAL' 폴더에 있는 하위 파일들을 모두 리스트로 만듦\n",
    "        normal_dir = os.path.join(data_dir, 'NORMAL')\n",
    "        for img in glob(f\"{normal_dir}/*\"): \n",
    "            self.image_paths.append(img)\n",
    "            self.labels.append(0)\n",
    "\n",
    "        pneumonia_dir = os.path.join(data_dir, 'NORMAL')\n",
    "        for img in glob(f\"{pneumonia_dir}/*\"): \n",
    "            self.image_paths.append(img)\n",
    "            self.labels.append(1)\n",
    "            \n",
    "    def __len__(self): \n",
    "        #len이건 필수래 나중에 DataLoader 하려면 \n",
    "        #몇번 반복해서 받을건지를 결정하는 요소? \n",
    "        #이미지파일 갯수만큼 받아야하니까\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        #이것도 필수래 DataLoader 에서 이터레이터한 객체를 받아올 수 있다는데? \n",
    "        #그래서 for문같은 반복문 추가 안해줘도 DataLoader에서 알아서 반복 해준대 ㅇㅇ\n",
    "        #이미지 경로를 받아서 실제 이미지를 열어주는 구간\n",
    "        \n",
    "        image= torchvision.io.read_image(self.image_paths[idx])\n",
    "        label= self.labels[idx]\n",
    "\n",
    "        if self.transform: \n",
    "            image= self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform= transforms.Compose([ \n",
    "    #데이터 전처리 하기위해서 필수인 과정 \n",
    "    #데이터 증강도 할 수 있음 +a인 느낌 \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.RandomHorizontalFlip(),      # 수평 뒤집기\n",
    "    transforms.RandomRotation(10),          # 10도 이내로 회전\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 밝기 및 대비 조절\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 회전 없이 이동 변환만 적용\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "])\n",
    "\n",
    "val_transform= transforms.Compose([\n",
    "    #검증 데이터셋을 만들 땐 전처리만\n",
    "    #데이터 증강은 필요없음. \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset= customdataset(data_dir= 'chest_xray/train', transform= train_transform) \n",
    "train_size= int(0.8*len(full_dataset)) \n",
    "val_size= len(full_dataset) - train_size\n",
    "train_dataset, val_dataset= random_split(full_dataset, [train_size, val_size]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Grayscale(num_output_channels=1)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ") Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Grayscale(num_output_channels=1)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(full_dataset.transform, train_dataset.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 검증 데이터는 데이터 증강을 적용하지 않기 때문에 변환을 따로 지정\n",
    "val_dataset.dataset = customdataset(data_dir='chest_xray/train', transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Grayscale(num_output_channels=1)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ") Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Grayscale(num_output_channels=1)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ") Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Grayscale(num_output_channels=1)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(full_dataset.transform, train_dataset.dataset.transform, val_dataset.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnhancedCNN(mm.Module): \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
